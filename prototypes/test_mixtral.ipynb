{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testig MistralClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Minstral (without streaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96mBased on the information provided, it takes 10 hours for one batch of 5 shirts to dry in the sun. To find out how long it will take to dry 20 shirts, we first need to determine how long it takes to dry one shirt:\n",
      "\n",
      "1 shirt = 5 shirts / 5\n",
      "1 shirt = 1 shirt\n",
      "\n",
      "Now we know that it takes 1 hour to dry one shirt (since it takes 10 hours to dry 5 shirts):\n",
      "\n",
      "Time to dry 1 shirt = 10 hours / 5 shirts = 2 hours / 1 shirt\n",
      "\n",
      "Finally, to find out how long it takes to dry 20 shirts, we can multiply the time it takes to dry one shirt by the number of shirts:\n",
      "\n",
      "Time to dry 20 shirts = 2 hours / 1 shirt * 20 shirts = 40 hours\n",
      "\n",
      "So, it will take 40 hours to dry 20 shirts in the sun.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Changing the API key file\n",
    "load_dotenv() # Para cargar .env\n",
    "\n",
    "  \n",
    "# Function to intect with the Mistral API and get a response\n",
    "def chat_mistral(user_content):\n",
    "  # Initialize the Mistral client with API key\n",
    "  api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "  model = 'mistral-tiny'\n",
    "  client = MistralClient(api_key=api_key)\n",
    "\n",
    "  # Prepare a list of ChatMessage objects with the user's content\n",
    "  messages = [ChatMessage(role='user', content=user_content)]\n",
    "\n",
    "  # Get the response from the Mistral API without streaming\n",
    "  chat_response = client.chat(model=model, messages=messages)\n",
    "\n",
    "  try:\n",
    "    # Extract the content from the response\n",
    "    response_content = chat_response.choices[0].message.content if chat_response.choices else \"\"\n",
    "  except AttributeError as e:\n",
    "    print(f'An error occurred while processing the response: {e}')\n",
    "    response_content = \"\"\n",
    "  \n",
    "  # Return the response content\n",
    "  return response_content\n",
    "\n",
    "CYAN = '\\033[96m'\n",
    "# ANSI escape code for yellow color\n",
    "YELLOW = '\\033[93m'\n",
    "# ANSI escape code to reset to default color\n",
    "RESET_COLOR = '\\033[0m'\n",
    "\n",
    "# Example usage\n",
    "user_content = \"Tengo que secar 5 camisas al sol. Luego de 10 horas todas las camisas están secas. \\\n",
    "  Al siguiente día tengo que secar 20 camisas, ¿qué tiempo me tomará?\"\n",
    "\n",
    "response = chat_mistral(user_content)\n",
    "print(f'{CYAN}{response}{RESET_COLOR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingResponse(id='embd-f93a54785b904ebca5c11626eb3d66f6', object='list', data=[EmbeddingObject(object='embedding', embedding=[-0.0295562744140625, -0.0178985595703125, 0.0177154541015625, 0.02166748046875, 0.0195465087890625, -0.011962890625, 0.05780029296875, 0.00487518310546875, 0.005107879638671875, -0.0190582275390625, -0.047760009765625, 0.0345458984375, -0.0236053466796875, -0.035125732421875, -0.0509033203125, 0.007305145263671875, -0.01313018798828125, -0.0079498291015625, 0.060028076171875, 0.03607177734375, -0.04376220703125, 0.041412353515625, -0.055816650390625, -0.0030574798583984375, -0.034332275390625, -0.00415802001953125, -0.009552001953125, -0.00864410400390625, -0.0509033203125, -0.00647735595703125, 0.0004870891571044922, -0.043609619140625, -0.034210205078125, -0.003719329833984375, 0.049530029296875, -0.0229644775390625, -0.045745849609375, -0.0509033203125, 0.02667236328125, 0.0189361572265625, -0.00623321533203125, -0.00522613525390625, -0.0016813278198242188, 0.054931640625, 0.01160430908203125, -0.053955078125, -0.021453857421875, 0.0014743804931640625, -0.01079559326171875, -0.00972747802734375, -0.0123748779296875, 0.033782958984375, 0.002902984619140625, -0.0025501251220703125, 0.02294921875, -0.00952911376953125, -0.0347900390625, -0.0255584716796875, -0.0311737060546875, 0.06365966796875, -0.0369873046875, 0.01180267333984375, 0.02520751953125, -0.0136566162109375, 0.022491455078125, 0.031341552734375, 0.0428466796875, -0.0364990234375, 0.035919189453125, 0.0011739730834960938, 0.0096435546875, -0.0172271728515625, -0.0265960693359375, 0.016082763671875, 0.0047149658203125, -0.08331298828125, -0.0171356201171875, -0.00785064697265625, 0.03436279296875, -0.0019330978393554688, -0.037689208984375, 0.0091552734375, 0.045196533203125, -0.04705810546875, -0.0167388916015625, 0.033050537109375, 0.01348114013671875, -0.00933837890625, 0.00010979175567626953, 0.00450897216796875, 0.032623291015625, -0.027130126953125, -0.01297760009765625, -0.01178741455078125, 0.049346923828125, 0.03765869140625, -0.01500701904296875, -0.0391845703125, -0.0011920928955078125, 0.032012939453125, 0.0411376953125, -0.027130126953125, 0.026123046875, -0.000720977783203125, 0.0295562744140625, -0.036529541015625, 0.002155303955078125, -0.020843505859375, -0.011505126953125, 0.009124755859375, -0.03753662109375, -0.003173828125, -0.01271820068359375, -0.05328369140625, 0.01806640625, -0.03277587890625, -0.0021152496337890625, 0.031494140625, -0.018585205078125, -0.04156494140625, 0.014892578125, 0.0003647804260253906, -0.03790283203125, 0.0263519287109375, -0.04052734375, -0.05096435546875, -0.01165008544921875, 0.0782470703125, -0.01090240478515625, -0.01401519775390625, -0.0202484130859375, 0.01216888427734375, -0.0313720703125, -0.050384521484375, -0.019378662109375, -0.0057373046875, 0.045440673828125, -0.0166473388671875, -0.0129241943359375, -0.0009593963623046875, 0.031463623046875, -0.043365478515625, -0.038299560546875, 0.004993438720703125, -0.0509033203125, 0.0112152099609375, -0.0202178955078125, 0.05670166015625, -0.029510498046875, -0.003963470458984375, -0.0021457672119140625, 0.04901123046875, 0.06829833984375, 0.012664794921875, -0.0086822509765625, -0.01015472412109375, -0.037628173828125, -0.0191650390625, 0.033660888671875, -0.001956939697265625, -0.01045989990234375, -0.043701171875, -0.0262298583984375, 0.01251983642578125, -0.007007598876953125, -0.0253143310546875, -0.0145263671875, 0.0180511474609375, -0.00646209716796875, -0.02008056640625, 0.016571044921875, -0.01053619384765625, 0.0687255859375, 0.0284271240234375, -0.021728515625, 0.0579833984375, 0.0102386474609375, -0.0059051513671875, 0.05621337890625, 0.0153656005859375, -0.0302734375, -0.006855010986328125, 0.037109375, -0.0087432861328125, 0.042144775390625, -0.03179931640625, -0.025970458984375, -0.0240936279296875, -0.033538818359375, 0.0106353759765625, -0.0089569091796875, -0.0270538330078125, -0.051910400390625, 0.0079498291015625, -0.036041259765625, 0.07415771484375, 0.01491546630859375, -0.0244598388671875, 0.033203125, -0.034454345703125, 0.043670654296875, -0.042266845703125, 0.009521484375, 0.066162109375, -0.031707763671875, 0.002288818359375, -0.004253387451171875, 0.046295166015625, -0.00350189208984375, -0.027496337890625, -0.03375244140625, 0.0013799667358398438, -0.01218414306640625, -0.038055419921875, -0.0127716064453125, 0.0265655517578125, 0.01050567626953125, -0.01947021484375, -0.051910400390625, -0.039520263671875, 0.026214599609375, -0.0221405029296875, -0.00446319580078125, -0.0119171142578125, 0.0232696533203125, 0.061767578125, -0.01059722900390625, -0.00833892822265625, -0.0277557373046875, 0.0190887451171875, 0.0462646484375, -0.025146484375, -0.01448822021484375, 0.0027713775634765625, 0.02410888671875, -0.0084228515625, 0.004230499267578125, 0.038360595703125, 0.0161285400390625, -0.0140380859375, -0.0088348388671875, 0.0190277099609375, -0.007038116455078125, 0.033355712890625, 0.038238525390625, -0.010345458984375, -0.00827789306640625, -0.0153656005859375, 0.046051025390625, 0.019439697265625, -0.05523681640625, -0.00933837890625, -0.0714111328125, -0.036865234375, -0.0265045166015625, -0.0218963623046875, -0.0194854736328125, -0.0224151611328125, 0.0809326171875, -0.0213165283203125, -0.0030727386474609375, -0.0228271484375, 0.0618896484375, -0.046875, 0.05126953125, 0.0194244384765625, -0.047149658203125, 0.02978515625, 0.0372314453125, -0.020355224609375, -0.019287109375, 0.01392364501953125, 0.040740966796875, -0.0017385482788085938, 0.040435791015625, -0.02105712890625, -0.0142974853515625, 0.03131103515625, -0.01282501220703125, 0.03717041015625, -0.07196044921875, 0.01004791259765625, 0.003063201904296875, 0.0239715576171875, -0.03570556640625, -0.05694580078125, -0.060546875, -0.00511932373046875, -0.03448486328125, -0.04901123046875, 0.013031005859375, 0.042938232421875, 0.035430908203125, -0.01629638671875, 0.0377197265625, -0.0248565673828125, 0.06280517578125, 0.0416259765625, 0.015838623046875, 0.021240234375, 0.0163726806640625, -0.0289764404296875, -0.0084075927734375, -0.01959228515625, 0.018402099609375, -0.034759521484375, -0.040985107421875, -0.006103515625, 0.023162841796875, -0.048919677734375, 0.006191253662109375, 0.02484130859375, -0.0035400390625, 0.033721923828125, -0.00879669189453125, 0.01116180419921875, -0.03753662109375, -0.032928466796875, 0.02093505859375, -0.01092529296875, -0.00717926025390625, -0.0292205810546875, 0.05206298828125, -0.0450439453125, 0.027252197265625, -0.0163421630859375, 0.00907135009765625, -0.01861572265625, -0.01361846923828125, -0.0498046875, 0.0243682861328125, -0.050079345703125, 0.041259765625, 0.0550537109375, 0.0022525787353515625, 0.0014295578002929688, 0.05078125, 0.03582763671875, -0.06439208984375, 0.0102996826171875, -0.0017080307006835938, -0.0006122589111328125, -0.023406982421875, -0.0187225341796875, -0.0201263427734375, -0.0262451171875, -0.0264739990234375, -0.0029144287109375, -0.0013151168823242188, 0.04571533203125, -0.0208282470703125, -0.0010919570922851562, 0.01174163818359375, 0.057220458984375, -0.00862884521484375, 0.08062744140625, -0.005725860595703125, -0.045867919921875, 0.0027446746826171875, 0.07806396484375, -0.04168701171875, -0.005157470703125, 0.05206298828125, 0.048980712890625, 0.032135009765625, 0.022796630859375, -0.000946044921875, 0.0364990234375, -0.0017728805541992188, -0.0038852691650390625, -0.005817413330078125, 0.006221771240234375, 0.033660888671875, 0.0127716064453125, 0.043914794921875, 0.01430511474609375, -0.004856109619140625, 0.008056640625, 0.00290679931640625, 0.00643157958984375, -0.032745361328125, 0.016448974609375, 0.0228729248046875, 0.0037784576416015625, 0.0132904052734375, -0.01178741455078125, -0.0112762451171875, 0.021026611328125, -0.052642822265625, 0.0684814453125, 0.023651123046875, 0.032440185546875, -0.018585205078125, 0.004825592041015625, 0.0225982666015625, 0.0091552734375, 0.015960693359375, 0.032257080078125, 0.048919677734375, -0.01317596435546875, -0.01351165771484375, -0.007556915283203125, 0.0667724609375, 0.025604248046875, 0.0094757080078125, 0.0136566162109375, -0.01212310791015625, 0.039215087890625, 0.00858306884765625, -0.0173797607421875, 0.0195159912109375, 0.040069580078125, -0.018310546875, 0.0276336669921875, 0.007965087890625, 0.009002685546875, -0.057830810546875, -0.0167694091796875, 0.01329803466796875, -0.0215911865234375, 0.0081939697265625, -0.00952911376953125, -0.045318603515625, -0.0286865234375, 0.060211181640625, -0.0821533203125, 0.01540374755859375, 0.01641845703125, -0.00464630126953125, 0.041229248046875, -0.02069091796875, -0.057525634765625, 0.037109375, -0.019775390625, -0.02886962890625, 0.0038852691650390625, -0.002414703369140625, 0.02203369140625, -0.00543212890625, -0.031402587890625, 0.00794219970703125, 0.0115966796875, 0.007633209228515625, 0.03533935546875, -0.00205230712890625, 0.020233154296875, 0.0205230712890625, 0.0003039836883544922, 0.0023632049560546875, -0.036895751953125, 0.053741455078125, -0.01555633544921875, -0.020477294921875, -0.0004279613494873047, 0.039825439453125, 0.016021728515625, -0.040435791015625, -0.01171875, -0.00720977783203125, 0.00017082691192626953, 0.006622314453125, 0.0224151611328125, -0.03277587890625, -0.032867431640625, -0.03997802734375, 0.00373077392578125, -0.0041961669921875, 0.08062744140625, 0.0008363723754882812, -0.0230255126953125, 0.022735595703125, -0.04742431640625, -0.0455322265625, -0.010589599609375, 0.021697998046875, 0.01113128662109375, 0.05572509765625, -0.0015802383422851562, -0.00734710693359375, -0.034576416015625, 0.07342529296875, -0.00952911376953125, 0.01435089111328125, -0.041046142578125, 0.051727294921875, 0.047760009765625, -0.06341552734375, -0.0241241455078125, 0.006103515625, 0.008148193359375, 0.042724609375, 0.01218414306640625, -0.005001068115234375, 0.01038360595703125, -0.0164794921875, -0.035797119140625, -0.0215301513671875, -0.007503509521484375, -0.038970947265625, 0.017486572265625, 0.01291656494140625, -0.0421142578125, -0.0023708343505859375, -0.01293182373046875, 0.0059051513671875, 0.022216796875, -0.0199432373046875, 0.00643157958984375, -0.0076904296875, -0.0227203369140625, -0.050811767578125, -0.0280609130859375, -0.0112152099609375, 0.0044097900390625, -0.035797119140625, 0.011016845703125, -0.03887939453125, 0.0182342529296875, -0.015777587890625, 0.0034770965576171875, -0.0487060546875, -0.046875, 0.00020372867584228516, -0.01016998291015625, 0.0479736328125, 0.005794525146484375, -0.014129638671875, 0.0002694129943847656, -0.0007739067077636719, -0.045928955078125, 0.0242767333984375, 0.0123291015625, 0.015625, 0.0445556640625, 0.0124053955078125, 0.032806396484375, -0.006622314453125, 0.0233917236328125, -0.00995635986328125, -0.032196044921875, -0.05096435546875, -0.01947021484375, 0.011505126953125, -0.0207366943359375, -0.024627685546875, 0.0169830322265625, -0.071044921875, 0.020538330078125, 0.0306396484375, 0.03900146484375, -0.0207977294921875, 0.0008406639099121094, -0.0076751708984375, -0.004528045654296875, -0.0038623809814453125, -0.0004591941833496094, 0.004093170166015625, -0.0450439453125, -0.007579803466796875, -0.008880615234375, 0.03314208984375, 0.01058197021484375, 0.00934600830078125, 0.0430908203125, 0.04412841796875, -0.04864501953125, 0.0234832763671875, -0.009033203125, -0.0135040283203125, 0.0031642913818359375, 0.0009322166442871094, 0.01332855224609375, 0.00032973289489746094, -0.0260009765625, 0.03759765625, 0.027496337890625, -0.014190673828125, 0.00994110107421875, 0.022552490234375, -0.0157318115234375, 0.0243377685546875, 0.025787353515625, -0.05108642578125, -0.05975341796875, -0.0014162063598632812, -0.0055084228515625, 0.0200347900390625, 0.0418701171875, -0.0201263427734375, -0.01311492919921875, -0.008819580078125, 0.03564453125, 0.004009246826171875, -0.049896240234375, -0.055877685546875, 0.016510009765625, 0.018890380859375, 0.035675048828125, -0.01216888427734375, 0.0665283203125, 0.05963134765625, -0.0274200439453125, -0.00447845458984375, 0.06591796875, 0.05120849609375, -0.0218353271484375, -0.048828125, -0.0399169921875, -0.0035648345947265625, -0.0633544921875, -0.0240478515625, 0.049041748046875, -0.0130157470703125, -0.0430908203125, 0.00475311279296875, -0.0099945068359375, -0.0214385986328125, 0.005634307861328125, -0.0025997161865234375, 0.0085906982421875, 0.015167236328125, -0.03204345703125, -0.07080078125, -0.00872039794921875, 0.003238677978515625, 0.0280609130859375, 0.072021484375, -0.0012197494506835938, -0.00745391845703125, -0.0200042724609375, 0.009124755859375, -0.01068115234375, -0.00727081298828125, -0.025421142578125, 0.01465606689453125, 0.048431396484375, 0.051025390625, 0.024383544921875, -0.0129241943359375, -0.0102386474609375, -0.00409698486328125, 0.050140380859375, 0.025054931640625, -0.004291534423828125, -0.055633544921875, -0.0162506103515625, 0.0110321044921875, -0.0009593963623046875, -0.01617431640625, -0.0248565673828125, -0.03497314453125, 0.0006575584411621094, -0.00872039794921875, 0.00821685791015625, -0.054107666015625, 0.009307861328125, 0.045562744140625, 0.005992889404296875, -0.05010986328125, 0.005130767822265625, -0.004596710205078125, -0.03558349609375, -0.005077362060546875, 0.014923095703125, -0.018096923828125, -0.05712890625, -0.048004150390625, 0.02545166015625, -0.03387451171875, -0.05218505859375, -0.01134490966796875, 0.06439208984375, 0.0023937225341796875, -0.00994873046875, -0.0462646484375, -0.007904052734375, -0.0275726318359375, -0.0241546630859375, -0.0513916015625, -0.006565093994140625, 0.031341552734375, -0.01416778564453125, -0.00905609130859375, 0.0026912689208984375, -0.0400390625, -0.0303497314453125, -0.0025844573974609375, -0.0323486328125, 0.01025390625, -0.020172119140625, 0.04193115234375, 0.013916015625, -0.006130218505859375, 0.0237274169921875, 0.043731689453125, -0.0168914794921875, -0.003173828125, -0.0011968612670898438, -0.04290771484375, -0.0020008087158203125, -0.00406646728515625, 0.011138916015625, -0.0311737060546875, -0.0162811279296875, 0.047943115234375, -0.06207275390625, 0.0165252685546875, 0.014495849609375, -0.05194091796875, -0.039031982421875, -0.00927734375, 0.00516510009765625, 0.0250244140625, 0.0491943359375, 0.042083740234375, -0.06072998046875, 0.0098114013671875, -0.046356201171875, 0.059417724609375, 0.0029125213623046875, -0.006099700927734375, -0.015777587890625, 0.0206756591796875, 0.005527496337890625, -0.03082275390625, -0.049896240234375, -0.055572509765625, -0.0233154296875, 0.00665283203125, 0.032135009765625, 0.0248565673828125, -0.0245513916015625, -0.0253448486328125, -0.030059814453125, -0.032684326171875, -0.00025010108947753906, -0.0023288726806640625, -0.006793975830078125, -0.019256591796875, -0.0012969970703125, -0.0208892822265625, -0.0718994140625, -0.0286865234375, -0.0025310516357421875, 0.001346588134765625, 0.0279388427734375, -0.0460205078125, 0.01904296875, 0.0092620849609375, 0.015838623046875, 0.05517578125, 0.04583740234375, 0.003345489501953125, -0.047454833984375, -0.00901031494140625, 0.00647735595703125, 0.03857421875, 0.0181884765625, -0.0101776123046875, 0.008544921875, 0.01030731201171875, -0.00539398193359375, 0.0234222412109375, 0.032623291015625, 0.007251739501953125, -0.07525634765625, -0.007190704345703125, 0.0156402587890625, 0.032196044921875, 0.059356689453125, 0.04376220703125, -0.00287628173828125, -0.0008683204650878906, -0.0789794921875, 0.042266845703125, 0.009307861328125, 0.0196990966796875, 0.01222991943359375, -0.034759521484375, -0.05804443359375, -0.07452392578125, -0.054901123046875, 0.0119171142578125, 0.006122589111328125, 0.03497314453125, 0.00818634033203125, -0.04095458984375, -0.004795074462890625, 0.03753662109375, 0.0126495361328125, 0.0570068359375, 0.048004150390625, -0.016021728515625, 0.0909423828125, -0.00433349609375, -0.009521484375, -0.0310821533203125, 0.02264404296875, 0.0289154052734375, 0.0139007568359375, 0.01270294189453125, -0.023284912109375, -0.0177154541015625, -0.0176544189453125, -0.01971435546875, 0.050506591796875, -0.0309295654296875, 0.0221405029296875, -0.043792724609375, -0.0029125213623046875, 0.007144927978515625, 0.0007762908935546875, -0.0146026611328125, -0.015869140625, -0.04119873046875, -0.11431884765625, -0.0035190582275390625, -0.0307769775390625, -0.01580810546875, 0.0031986236572265625, -0.0295257568359375, 0.032012939453125, 0.0018815994262695312, 0.037322998046875, 0.003139495849609375, -0.0224609375, -0.024993896484375, 0.00316619873046875, -0.0284881591796875, 0.033172607421875, 0.017486572265625, -0.05877685546875, 0.01678466796875, 0.01351165771484375, -7.224082946777344e-05, 0.00592803955078125, 0.01224517822265625, -0.049407958984375, -0.005916595458984375, -0.0223541259765625, -0.0013856887817382812, 0.039764404296875, -0.0070953369140625, 0.01523590087890625, -0.0216064453125, 0.03076171875, -0.0008654594421386719, -0.02105712890625, 0.042449951171875, -0.0116729736328125, -0.01910400390625, 0.01277923583984375, 0.00927734375, 0.0250091552734375, -0.01104736328125, 0.02752685546875, 0.041015625, -0.0003674030303955078, -0.0149383544921875, -0.022796630859375, -0.01407623291015625, 0.03887939453125, 0.0157470703125, 0.0298004150390625, 0.0308074951171875, 0.00447845458984375, -0.00341033935546875, -0.0271453857421875, -0.0196380615234375, 0.038848876953125, -0.02093505859375, -0.05474853515625, 0.01172637939453125, 0.034912109375, 0.046844482421875, -0.037933349609375, 0.01264190673828125, 0.0328369140625, -0.00580596923828125, 0.013763427734375, 0.017974853515625, -0.02490234375, -0.00789642333984375, 0.0187530517578125, 0.00876617431640625, -0.040557861328125, 0.039031982421875, 0.049468994140625, -0.0153656005859375, -0.0009722709655761719, 0.0218353271484375, -0.0020198822021484375, 0.07745361328125, 0.0301055908203125, 0.016326904296875, -0.09918212890625, 0.027008056640625, 0.0104522705078125, 0.0015153884887695312, 0.0085601806640625, -0.03228759765625, 0.01175689697265625, 0.038055419921875, -0.02392578125, 0.0032100677490234375, 0.002445220947265625, 0.08135986328125, -0.0030517578125, -0.035308837890625, 0.004634857177734375, 0.033935546875, 0.0206451416015625, -0.060821533203125, -0.020599365234375, 0.022796630859375, 0.0076751708984375, 0.0266571044921875, 0.04241943359375, -0.014556884765625, 0.0626220703125, -0.0113677978515625, -0.021942138671875, 0.032806396484375, -0.002819061279296875, -0.0196990966796875, -0.004528045654296875, -0.01342010498046875, 0.03289794921875, 0.0138092041015625, 0.03131103515625, 0.048187255859375, 0.03497314453125, 0.00958251953125, -0.01373291015625, -0.0439453125, -0.01119232177734375, 0.018035888671875, -0.010284423828125, 0.0175018310546875, 0.021453857421875, -0.001605987548828125, 0.06268310546875, 0.01303863525390625, 0.019775390625, 0.05413818359375, -0.0699462890625, 0.039215087890625, -0.07647705078125, -0.005588531494140625, 0.0177459716796875, 0.0006914138793945312, -0.01154327392578125, -0.028472900390625, 0.0010614395141601562, -0.0304107666015625, -0.043426513671875, -0.0196380615234375, 0.012847900390625, -0.054595947265625, 0.04534912109375, 0.056304931640625, 0.0042724609375, 0.04425048828125, -0.06317138671875, 0.06536865234375, 0.01544952392578125, 0.0028896331787109375, 0.0008234977722167969, -0.0129241943359375, 0.022735595703125, -0.010498046875, 0.004375457763671875, -0.0029201507568359375, 0.0255126953125, 0.006259918212890625, 0.04693603515625, 0.0045013427734375, -0.050872802734375, -0.015289306640625, -0.0197296142578125, -0.061859130859375, 0.021331787109375, 0.05810546875, -0.01311492919921875, 0.0131072998046875, 0.0247955322265625, 0.00511932373046875, -0.0253448486328125, 0.01153564453125, 0.0025386810302734375, -0.02557373046875, -0.017547607421875, -0.0377197265625, 0.045989990234375, -0.01141357421875, 0.044219970703125, -0.029022216796875, 0.039306640625, -0.00894927978515625, 0.00748443603515625, -0.06036376953125, 0.0128631591796875, 0.0186614990234375, 0.06402587890625, -0.05975341796875, 0.035003662109375, 0.050384521484375, 0.0295867919921875, -0.07855224609375, -0.0015811920166015625, 0.0252838134765625, 0.0396728515625, 0.01461029052734375, -0.0237579345703125, -0.0202178955078125, 0.005039215087890625, 0.0146484375, 0.0457763671875, -0.01200103759765625, 0.038330078125, -0.02667236328125, -0.0178375244140625, -0.0131378173828125, -0.0440673828125], index=0)], model='mistral-embed', usage=UsageInfo(prompt_tokens=7, total_tokens=7, completion_tokens=0))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "#import asyncio\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv() # Para cargar .env\n",
    "\n",
    "def embed_mistral(user_content):\n",
    "    api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "    client = MistralClient(api_key=api_key)\n",
    "    embedding_response = client.embeddings(\n",
    "        model ='mistral-embed',\n",
    "        input = user_content,\n",
    "    )\n",
    "    return embedding_response\n",
    "\n",
    "# async def async_embed_mistral(user_content):\n",
    "#     api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "#     client = MistralClient(api_key=api_key)\n",
    "#     embedding_response = await client.embeddings(\n",
    "#         model ='mistral-embed',\n",
    "#         input = user_content * 10\n",
    "#     )\n",
    "\n",
    "text = \"Hello from TechNision\"\n",
    "enbeded_text = embed_mistral(text)\n",
    "enbeded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m task2\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Ejecutar el bucle de eventos de asyncio para ejecutar las tareas\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/asyncio/runners.py:186\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def greet(name):\n",
    "    print(f\"¡Hola, {name}!\")\n",
    "    await asyncio.sleep(2)  # Simula una operación que toma 2 segundos\n",
    "    print(f\"¡Adiós, {name}!\")\n",
    "\n",
    "async def main():\n",
    "    # Ejecutar dos saludos de manera concurrente\n",
    "    task1 = asyncio.create_task(greet(\"Alice\"))\n",
    "    task2 = asyncio.create_task(greet(\"Bob\"))\n",
    "\n",
    "    # Esperar a que ambas tareas se completen\n",
    "    await task1\n",
    "    await task2\n",
    "\n",
    "# Ejecutar el bucle de eventos de asyncio para ejecutar las tareas\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic prompt + model + output partser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Si todas las camisas se secan al sol en 10 horas, entonces podemos decir que se seca 1 camisa cada 2 horas (10 horas / 5 camisas = 2 horas por camisa).\\n\\nSi al siguiente día tienes que secar 20 camisas, entonces tomará 2 horas por camisa multiplicado por 20 camisas, lo que nos da un total de 40 horas.\\n\\nPor lo tanto, te tomará 40 horas secar las 20 camisas al sol al día siguiente.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "load_dotenv() # Para cargar .env\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 1. Prompt \n",
    "prompt = ChatPromptTemplate.from_template(\"Tengo que secar 5 camisas al sol. Luego de 10 horas todas las camisas están secas. Al siguiente día tengo que secar {num_camisas} camisas, ¿qué tiempo me tomará?\")\n",
    "\n",
    "# 2a. Chat Model\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(\n",
    "  model='gpt-3.5-turbo-0613',\n",
    "  api_key=openai_api_key\n",
    "  )\n",
    "\n",
    "# 3. Parsert instantion\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 4. chaining\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# 5. Invoke\n",
    "chain.invoke({'num_camisas': '20'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nEl tiempo que te tomará dependerá de factores como la intensidad del sol y la humedad del ambiente, pero considerando que se mantienen las mismas condiciones, podrías estimar que te tomará aproximadamente 40 horas, ya que estarías secando cuatro veces más camisas que en el primer día. Sin embargo, es importante tener en cuenta que el proceso de secado puede ser más rápido o más lento según las condiciones mencionadas anteriormente. '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2a. LLM Model\n",
    "from langchain_openai.llms import OpenAI\n",
    "llm = OpenAI(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  api_key=openai_api_key)\n",
    "\n",
    "# 3. Parsert instantion\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 4. chaining\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "# 5. Invoke\n",
    "message = chain.invoke({'num_camisas': '20'})\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Si tienes suficiente espacio para tender 20 camisas al sol y las condiciones climáticas son similares, entonces deberían secarse en el mismo tiempo, es decir, 10 horas. Esto se debe a que el tiempo de secado depende del ambiente y las propiedades de absorción de la humedad de las camisas, no del número de camisas que estás secando.\\n\\nSin embargo, si el espacio es limitado y debes tender las 20 camisas en lotes, entonces el tiempo de secado completo será mayor a 10 horas. Por ejemplo, si puedes tender solo 5 camisas a la vez, necesitarías 4 lotes para secar las 20 camisas, lo que requeriría 40 horas en total (10 horas * 4 lotes). \\n\\nEspero que esta información te sea útil. Si tienes alguna otra pregunta, no dudes en preguntarme.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2a. LLM Model\n",
    "# Changing the API key file\n",
    "load_dotenv() # Para cargar .env\n",
    "mistral_api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "chat_mistral = ChatMistralAI(\n",
    "  model=\"mistral-small\",\n",
    "  api_key=mistral_api_key)\n",
    "\n",
    "# 3. Parsert instantion\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 4. chaining\n",
    "chain = prompt | chat_mistral | output_parser\n",
    "\n",
    "# 5. Invoke\n",
    "message = chain.invoke({'num_camisas': '20'})\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MistralEmbeddings' from 'langchain_community.embeddings' (/Users/Eber/Library/CloudStorage/OneDrive-Personal/Documentos/3. TechNision/Projects/Data_extractor_from_documents/.venv/lib/python3.11/site-packages/langchain_community/embeddings/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MistralEmbeddings\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'MistralEmbeddings' from 'langchain_community.embeddings' (/Users/Eber/Library/CloudStorage/OneDrive-Personal/Documentos/3. TechNision/Projects/Data_extractor_from_documents/.venv/lib/python3.11/site-packages/langchain_community/embeddings/__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG search from documen in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'embed_documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embedding_response\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 2. Vectostore\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mharrison worked at kensho\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43membedding_mistral\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# 3. Retrival\u001b[39;00m\n\u001b[1;32m     31\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vectorstore\u001b[38;5;241m.\u001b[39mas_retriever()\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Documentos/3. TechNision/Projects/Data_extractor_from_documents/.venv/lib/python3.11/site-packages/langchain_community/vectorstores/faiss.py:913\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    894\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[1;32m    895\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \n\u001b[1;32m    897\u001b[0m \u001b[38;5;124;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;124;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 913\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m(texts)\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__from(\n\u001b[1;32m    915\u001b[0m         texts,\n\u001b[1;32m    916\u001b[0m         embeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    921\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'embed_documents'"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from mistralai.client import MistralClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv() # Para cargar .env\n",
    "\n",
    "# 1. Enbedding\n",
    "def embedding_mistral(user_content):\n",
    "    api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "    client = MistralClient(api_key=api_key)\n",
    "    embedding_response = client.embedding(\n",
    "        model ='mistral-embed',\n",
    "        input = user_content,\n",
    "    )\n",
    "    return embedding_response\n",
    "\n",
    "\n",
    "# 2. Vectostore\n",
    "vectorstore = FAISS.from_texts(\n",
    "    ['harrison worked at kensho'], \n",
    "    embedding = embedding_mistral\n",
    ")\n",
    "\n",
    "# 3. Retrival\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 4. prompt\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 5. Chatmodel\n",
    "chat_mistral = ChatMistralAI(\n",
    "  model=\"mistral-small\",\n",
    "  api_key=mistral_api_key)\n",
    "\n",
    "# 6. chain\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | chat_mistral\n",
    "    | StrOutputParser()     \n",
    ")\n",
    "\n",
    "# 7. invoke\n",
    "result = chain.invoke(\"Where did harrison work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "load_dotenv() # Para cargar .env\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 1. Vector store\n",
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "  texts = [\"harrizon worked at kensho\", \"bears like to eat honey\"],\n",
    "  metadata = {},\n",
    "  embedding = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    api_key=openai_api_key\n",
    "  )\n",
    ")\n",
    "\n",
    "# 2. retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 3. Prompt\n",
    "template = \"\"\"Answers only in spanish the question based only on the following context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 4. model\n",
    "model = ChatOpenAI(\n",
    "  model='gpt-3.5-turbo-0613',\n",
    "  api_key=openai_api_key\n",
    "  )\n",
    "\n",
    "# parser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "setup_and_retrieval = RunnableParallel(\n",
    "  {'context': retriever, 'question': RunnablePassthrough()}\n",
    ")\n",
    "\n",
    "chain = setup_and_retrieval | prompt | model | output_parser\n",
    "\n",
    "# output\n",
    "response = chain.invoke(\"Where did harrison work?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid data input: \n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, ValidationError\n",
    "\n",
    "# Defining model\n",
    "class User(BaseModel):\n",
    "    id: int\n",
    "    username: str\n",
    "    email: str\n",
    "\n",
    "# Correct data input\n",
    "input_data_correct = {\n",
    "    'id': 1,\n",
    "    'username': 'john_doe',\n",
    "    'email': 'john@technision.io'\n",
    "}\n",
    "\n",
    "# Incorrect data input\n",
    "input_data_incorrect = {\n",
    "    'id': 2,\n",
    "    'username': 'jane_smith'\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Check data input\n",
    "    user1 = User(**input_data_correct)\n",
    "    print('Valid data input: '.format(user1))\n",
    "except ValidationError as e:\n",
    "    print('Validation Error: {}'.format(e))\n",
    "\n",
    "# try:\n",
    "#     # Trying to valid incorrect data\n",
    "#     user2 = User(**input_data_incorrect)\n",
    "#     print('Valid data input: '.format(user2))\n",
    "# except ValidationError as e:\n",
    "#     print('Validation error: {}'.format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing `DocArrayInMemorySearch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for DocArrayDoc\ntext\n  Field required [type=missing, input_value={'embedding': [-0.0090137... -0.007030032780268735]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.5/v/missing\nmetadata\n  Field required [type=missing, input_value={'embedding': [-0.0090137... -0.007030032780268735]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.5/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# try search\u001b[39;00m\n\u001b[1;32m     18\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m¿Qué es el POI?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 19\u001b[0m similar_docs \u001b[38;5;241m=\u001b[39m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m similar_docs:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(doc\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Documentos/3. TechNision/Projects/Data_extractor_from_documents/.venv/lib/python3.11/site-packages/langchain_community/vectorstores/docarray/base.py:127\u001b[0m, in \u001b[0;36mDocArrayIndex.similarity_search\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, k: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m    117\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m        List of Documents most similar to the query.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m results]\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Documentos/3. TechNision/Projects/Data_extractor_from_documents/.venv/lib/python3.11/site-packages/langchain_community/vectorstores/docarray/base.py:106\u001b[0m, in \u001b[0;36mDocArrayIndex.similarity_search_with_score\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    Lower score represents more similarity.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m query_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding\u001b[38;5;241m.\u001b[39membed_query(query)\n\u001b[0;32m--> 106\u001b[0m query_doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoc_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_embedding\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    107\u001b[0m docs, scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoc_index\u001b[38;5;241m.\u001b[39mfind(query_doc, search_field\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m, limit\u001b[38;5;241m=\u001b[39mk)\n\u001b[1;32m    109\u001b[0m result \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    110\u001b[0m     (Document(page_content\u001b[38;5;241m=\u001b[39mdoc\u001b[38;5;241m.\u001b[39mtext, metadata\u001b[38;5;241m=\u001b[39mdoc\u001b[38;5;241m.\u001b[39mmetadata), score)\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m doc, score \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(docs, scores)\n\u001b[1;32m    112\u001b[0m ]\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/Documentos/3. TechNision/Projects/Data_extractor_from_documents/.venv/lib/python3.11/site-packages/pydantic/main.py:164\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    163\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m \u001b[43m__pydantic_self__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__pydantic_self__\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for DocArrayDoc\ntext\n  Field required [type=missing, input_value={'embedding': [-0.0090137... -0.007030032780268735]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.5/v/missing\nmetadata\n  Field required [type=missing, input_value={'embedding': [-0.0090137... -0.007030032780268735]}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.5/v/missing"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Text examples\n",
    "texts = [\n",
    "    'El PEI es un documento de planeamiento a nivel pliego constituido por OEI y AEI',\n",
    "    'El POI es un documento de planeamiento a nivel UE constituido por AO e inversiones',\n",
    "    'El PESEM es un documento de planeamiento a nivel sectorial constituido por OES y AES',\n",
    "]\n",
    "\n",
    "# Start enbedding\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# Instancia de DocArrayInMemorySearch\n",
    "db = DocArrayInMemorySearch.from_texts(texts, embedding)\n",
    "\n",
    "# try search\n",
    "query = \"¿Qué es el POI?\"\n",
    "similar_docs = db.similarity_search(query, metadata={})\n",
    "\n",
    "for doc in similar_docs:\n",
    "    print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing agents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
